---
title: "Übung 5: Regressionsanalyse"
author: "Annie Waldherr"
output:
html_document: default
date: "2024-11-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999) # keine wissenschaftliche Schreibweise sehr kleiner Werte
```

## Überblick und Lernziele

Dieses Tutorial gibt eine Einführung in die bivariate lineare Regressionsanalyse. Sie lernen, wie man:

-   Daten für eine Regressionsanalyse vorbereitet,
-   eine lineare Beziehung visualisiert,
-   ein Regressionsmodell berechnet und interpretiert,
-   die Voraussetzungen einer linearen Regression überprüft,
-   eine Regression mit Bootstrapping durchführt.

## Das Arbeitsverzeichnis

Wie immer prüfen wir zuerst mit "getwd()", unter welchem Pfad unser Arbeitsverzeichnis ist. Alle Skripte und Datensätze, mit denen wir arbeiten wollen, sollten in diesem Ordner abgelegt sein.

```{r Working Directory}
##Arbeitsverzeichnis checken
getwd()
```

## Pakete installieren und laden

Dann laden wir wieder mit dem Paket "pacman" die nötigen R-Pakete.

```{r Pakete installieren}
##Pakete installieren und laden
if (!require("pacman")) {install.packages("pacman"); library(pacman)}
p_load(mosaic, knitr, tidyverse, broom, car, ggplot2, lmtest)
```

## Daten einlesen

Für diese Übung verwenden wir einen echten empirischen Datensatz aus dem European Social Survey: ESS Round 8 (2016): integrated file, edition 2.3, zu finden unter: <https://ess-search.nsd.no/en/study/f8e11f55-0c14-4ab3-abde-96d3f14d3c76>

Der ESS ist eine wissenschaftlich begleitete länderübergreifende Umfrage, die seit 2001 in ganz Europa durchgeführt wird. Alle zwei Jahre werden Face-to-Face-Interviews mit neu ausgewählten Querschnittsstichproben durchgeführt. Nähere Informationen über die Variablen und ihre Kodierung finden sich im zugehörigen Codebuch, welches mit den Daten zur Verfügung gestellt wird.

```{r Daten laden}
#Datensatz laden
df <- read.csv("ESS8e02_3.csv")
```

```{r Daten inspizieren, eval=FALSE}
#Datensatz inspizieren
class(df)
dim(df)
head(df)
glimpse(df)
```

Der Datensatz ist sehr groß, weshalb wir ihn im nächsten Schritt filtern. Uns interessieren nur die Datensätze von österreichischen Befragten (cntry==AT). Außerdem verwenden wir für die weitere Analyse nur die Auswahl folgender Variablen/Spalten: Gender (gndr), Age of respondent calculated (agea), News about politics and current affairs (nwspol), Internet use (netustm), Confident in own ability to participate (cptppola).

Wir legen mit dem Operator %\>% eine Pfeife an und nutzen hier nacheinander die Funktionen "filter" für die Auswahl der Fälle/Zeilen und "select" für die Auswahl der Variablen/Spalten aus dem tidyverse-Paket. Da der Name der Funktion "select" nicht eindeutig ist, müssen wir R mit "dplyr::select" einen konkreten Hinweis geben, damit es die select-Funktion aus dem Paket "dplyr" (welches Teil des tidyverse ist) verwendet. Ansonsten kann es zu Fehlermeldungen aufgrund von Konflikten mit anderen Paketen kommen.

```{r Daten filtern}
#Fälle filtern und Variablen auswählen
df_at <- df %>% 
  filter(cntry == "AT") %>%
  dplyr::select(idno, gndr, agea, nwspol, netustm, cptppola)

glimpse(df_at)
head(df_at)
```

Mit View() können wir uns den gefilterten Datensatz im Dateneditor anschauen. Damit wir in zukünftigen Übungen direkt mit dem österreichischen Teildatensatz arbeiten können, schreiben wir den Dataframe "df_at" mit dem folgenden Befehl in einen csv-File. Dieser wird autmatisch im Arbeitsverzeichnis abgelegt.

```{r gefilterten Datensatz speichern, eval = F}
View(df_at)
write.csv(df_at, file = "ESS8e02_3_AT.csv")
```

## UV und AV definieren

Wir wollen prüfen, welchen Einfluss die Internetnutzung der Befragten (netustm) auf ihre politische Nachrichtennutzung (nwspol) hat. Die Variable "netustm" ist also unsere unabhängige Variable (UV,Prädiktor), die Variable "nwspol" unsere abhängige Variable (AV, Kriterium). Beide Variablen sind metrisch, was den Voraussetzungen für eine Regressionsanalyse entspricht. Sowohl Internetnutzung (UV) als auch der politische Nachrichtenkonsum (AV) wurde in Minuten gemessen.

Nullhypothese H0: Die Internetnutzung der Befragten hat keinen Einfluss auf ihren politischen Nachrichtenkonsum.

Alternativhypothese H1: Je länger die Befragen das Internet nutzen, desto mehr politische Nachrichten konsumieren sie.

Mit dem unten stehenden Code, der Ihnen aus den vorigen Übungen bekannt ist, definieren wir unsere UV und AV und vergeben die zugehörigen Labels.

UV Internetnutzung (netustm) und AV politische Nachrichtennutzung (nwspol)

```{r Variablen auswählen}
#UV und AV definieren
df_at$uv <- df_at$netustm
df_at$av <- df_at$nwspol

#Labels vergeben
label_av <- "Politischer Nachrichtenkonsum"
label_uv <- "Internetnutzung"

glimpse(df_at)
```

Wenn wir den Datensatz genauer inspizieren (z.B. indem wir "View()" in die Konsole eingeben), sehen wir, dass unsere Variablen teils sehr hohe Werte außerhalb des gültigen Wertebereichs enthalten, wie z.B. 7777, 8888 oder 9999. Solche Werte werden üblicherweise verwendet, um fehlende Werte zu kennzeichnen. Ein Blick ins Codebuch zeigt uns auch, was diese Werte für die UV "nwspol" bedeuten: 7777 = Refusal, 8888 = Don't know, 9999 = No answer. Alle werden als "missing values" gekennzeichnet. Für die AV "netustm" sind die die fehlenden Werte: 66666 = not applicable 7777 = Refusal, 8888 = Don't know und 9999 = No answer.

Diese Information geben wir nun R, indem wir die UV und die AV so umkodieren, dass für die fehlenden Werte jeweils "NA" eingetragen wird.

```{r fehlende Werte}
#Fehlende Werte umkodieren
df_at$uv <- Recode((df_at$uv), 
                '6666 = NA; 7777 = NA; 8888 = NA; 9999 = NA')

df_at$av <- Recode((df_at$av), 
                '7777 = NA; 8888 = NA; 9999 = NA')
```

## Datenexploration und erste Voraussetzungsprüfung

Nun lassen wir uns zunächst mit der Funktion "favstats" die wichtigsten deskriptiven Statistiken für die UV und die AV ausgeben.

```{r Deskriptive Statistiken}

#Deskriptive Statistiken

des_stats <- rbind("Internetnutzung" = favstats(df_at$uv, na.rm = T), "Politischer Nachrichtenkonsum" = favstats(df_at$av, na.rm = T))

kable(des_stats, digits=2, col.names = c("Minimum", "Q1", "Median","Q3", "Maximum", "Mittelwert", "SD", "n", "Fehlend"))
```

In der Statistik werden uns auch für beide Variablen die Zahl der jeweils gültigen (n) und fehlenden Werte angegeben.

Für die weiteren Analysen wollen wir die Fälle mit fehlenden Werten ausschließen. Dies erreichen wir wieder mit der Funktion "drop_na", die wir auf beide Variablen, UV und AV, anwenden. Es werden also alle Fälle ausgeschlossen, die fehlende Werte in der UV oder AV aufweisen.

```{r Fehlende Werte ausschließen}

#Fälle mit fehlenden Werten ausschließen

df_at <- drop_na(df_at, uv, av)
```

Um einen ersten Eindruck über die Verteilungen der Daten zu gewinnen, erstellen wir Boxplots für die AV und die UV.

```{r Boxplots}

boxplot(df_at$av, main = label_av)
boxplot(df_at$uv, main = label_uv)

```

Eine wichtige Voraussetzung für die Regressionsanalyse ist eine lineare Beziehung zwischen UV und AV. Um dies zu beurteilen, erstellen wir mit der Funktion "ggplot" aus dem Paket "ggplot2" ein Streudiagramm (Scatterplot), mit dem der Zusammenhang zwischen zwei Variablen visualisiert wird. In diesem werden alle Fälle als Punkte in einem zweidimensionalen Koordinatensystem dargestellt. Auf der x-Achse tragen wir die Werte der AV, auf der y-Achse die Werte der UV ab (andersherum ist es genauso möglich). Jeder Datenpunkt repräsentiert also ein Wertepaar der beiden Variablen.

Zunächst legen wir mit "ggplot" das Grafikobjekt "scatter" an und weisen diesem die wichtigsten Informationen über die verwendeten Daten (df_at) und die Variablen für den Plot zu. Das Argument "aes" steht für "aesthetic mapping". Mit ihm ordnen wir die AV der x-Achse und die UV der y-Achse zu.

Dann verwenden wir dieses Objekt und fügen ihm weitere Elemente hinzu:

-   geom_point(): Dies fügt die Punkte im Koordinatensystem ein.
-   geom_smooth(method = "lm"): Hiermit fügen wir eine lineare Regressionsgerade hinzu.
-   labs(x = label_av, y = label_uv): Wir legen die Beschriftung der Achsen gemäß der oben definierten Labels fest.

```{r Streudiagramm mit ggplot2}
scatter <- ggplot(df_at, aes(av, uv))
scatter + geom_point() + geom_smooth(method = "lm") + labs(x = label_av, y = label_uv)
```

Wir können durchaus einen, wenn auch schwachen, linearen Trend in den Daten erkennen. Es macht also Sinn mit der linearen Regressionsanalyse fortzufahren.

## Einfache Regression

Um die Regression durchzuführen, verwenden wir die Funktion "lm" (linear model) und weisen sie einem Objekt zu, welches wir "model" nennen. Die AV fügen wir vor der Tilde, die UV hinter der Tilde ein. Als Datensatz verwenden wir wieder "df_at". Anschließend wenden wir die Funktion "summary" auf das Objekt "model" an. Damit erhalten wir die Zusammenfassung der Ergebnisse.

```{r Regression}
model <- lm(av ~ uv, data = df_at)
summary(model)
```

Im Output sehen wir zuerst noch einmal unseren Aufruf (Call), dann deskriptive Statistiken über die Residuen (Residuals) und danach die Koeffizienten und die zugehörigen Statistiken (Coefficients). In der Tabelle der Koeffizienten finden wir in der ersten Spalte (Estimate) die unstandardisierten Regressionskoeffizienten, dann die Standardfehler, t-Werte und die korrespondierenden p-Werte, die uns sagen, ob die Regressionskoeffizienten signifikant sind.

Mit der Information in der ersten Spalte können wir unsere Regressionsgerade zusammenstellen.

y = 43.972100 + 0.006946x

Inhaltlich bedeutet dies, dass mit jeder Minute Internetnutzung der politische Nachrichtenkonsum um einen Skalenpunkt steigt. Dieser Effekt ist aber mit p\<0.001 höchst signifikant.

Unter der Tabelle fügt R weitere Informationen zum Standardfehler der Residuen, zur Güte des Modells (R-Quadrat) und die F-Statistik zum zugehörigen Regressionsmodell bei. Hier interessieren uns v.a. die Informationen zum R-Quadrat.

Wir erhalten beides, das (multiple) R-Quadrat sowie das korrigierte R-Quadrat. Wir berichten immer das korrigierte R-Quadrat! Es gibt uns an, wieviel der Varianz in der AV durch unser Regressionsmodell erklärt wird. Unser Modell erklärt nur fast 100% der Gesamtvarianz in unseren Daten. Das ist sehr wenig.

## Residuenanalyse zur Voraussetzungsprüfung

Die Regressionsanalyse ist einerseits voraussetzungsreich, andererseits aber auch sehr robust gegen Verletzungen ihrer Voraussetzungen. Dies bedeutet, dass es meist nicht weiter schlimm ist, wenn einige der Voraussetzungen zumindest etwas verletzt werden. Die Prüfung sollte aber vorgenommen und berichtet werden.

-   *Skalenniveau*: Eine wichtige Voraussetzung, die unbedingt erfüllt sein muss, ist, dass die AV metrisch ist. Die UV kann metrisch oder nominal (dichotom) sein. Dies ist in unserem Beispiel, wie oben bereits erläutert, der Fall.
-   *Linearität*: Ein Regressionsmodell wird nur zuverlässige Ergebnisse bringen, wenn auch eine lineare Beziehung zwischen den Variablen besteht. Dies haben wir oben mit Sichtprüfung des Streudiagramms bereits festgestellt.

Es gibt drei weitere Voraussetzungen, die wir anhand einer Analyse der Residuen überprüfen. Dies sind jeweils die Abweichungen unserer Beobachtungen zur Regressionsgerade, also die Fehlervarianz, die nicht durch unser Regressionsmodell erklärt wird. Hierzu stellt uns R vier Plots zur Verfügung, die wir ganz einfach mit der Funktion "plot" aufrufen können, wenn wir sie auf unserem zuvor berechneten Modell "model" ausführen.

```{r Residualplots}
plot(model)
```

-   *Homoskedastizität*: Wie bei der Varianzanalyse soll es keine systematischen Unterschiede in der Varianz geben. Dies prüfen wir bei der Regressionsanalyse anhand der Residuen. Diese sollen keine systematische Varianz mehr aufweisen. Dies prüfen wir anhand der Plots 1 und 3, die jeweils die Residuen gegenüber den vorhergesagten Werten (fitted values) abtragen. Idealerweise verteilen sich die Punkte in beiden Plots gleichmäßig um die rote Linie. In Plot 1 sollen die Residuen zudem einen Mittelwert von 0 aufweisen. In unserem Beispiel sehen wir leider Abweichungen gerade im höheren Wertebereich.

-   *Normalverteilung der Residuen*: Auch sollen die Residuen möglichst normalverteilt sein. Dies prüfen wir anhand des Q-Q-Plots (Plot 2), der die Quartile der standardisierten Residuen gegenüber den Quartilen der Normalverteilung abträgt. Hier sollen die Punkte möglichst nah an der roten Linie bleiben. Für unsere Daten sehen wir, dass die Daten im Großen und Ganzen dem Trend der roten Linie folgen, teilweise jedoch deutlich davon abweichen.

-   *Ausreißeranalyse*: Ausreißer können die Ausrichtung der Regressionsgerade übermäßig verschieben. Es ist wichtig zu prüfen, ob Ausreißer bestehen und ob diese inhaltlich Sinn machen. Wenn es sich um fehlerhafte Werte handelt, sind diese zu löschen. Ausreißer haben wir bereits mit Hilfe der Boxplots identifizieren können. Zusätzlich gibt uns Plot 4 Informationen über den Einfluss möglicher Ausreißer auf das Regressionsmodell: zum einen gibt der Leverage-Wert auf der x-Achse des Plots Information über die Hebelwirkung einzelner Werte und bestimmt sich danach, wie weit der Wert einer UV von anderen Werten entfernt liegt. Ein hoher Hebelwert bedeutet, dass sich in der Nähe dieses Falls keine weiteren Fälle befinden und dieser daher potenziell großen Einfluss auf das gesamte Regressionsmodell hat. Plot 4 hebt jweils die drei Datenpunkte mit der höchsten Hebelwirkung hervor. Ein weiterer Anhaltspunkt ist Cook's Distance: diese bezieht sich auf das Ausmaß, in dem sich die Koeffizienten im Modell ändern würden, wenn ein bestimmter Fall aus dem Datensatz entfernt würde. Problematisch sind Werte, die außerhalb (hier unterhalb) der grauen gestrichelten Linie liegen, in unserem Beispiel bei 3 Standardabweichungen. In unserem Beispiel liegen alle Werte oberhalb der gestrichelten Linie und sind daher nicht problematisch.

Um die Sichtprüfung der Plots abzusichern, lassen sich zusätzlich Tests auf Homoskedastizität (Breusch-Pagan Test) und Normalverteilung (Shapiro-Wilk) der Residuen durchführen.

```{r Homoskedastizität}
bptest(model)
#Breusch-Pagan Test auf Homoskedastizität

shapiro.test(residuals(model))
#Test auf Normalverteilung der Residuen
```

Beide Tests werden in unserem Fall signifikant, d.h. die beiden Annahmen der Homoskedastizität und der Normalverteilung der Residuen werden verletzt. Nun kann man entweder mit dem Hinweis auf die Robustheit der Regressionsanalyse auf Verletzung ihrer Annahmen dennoch die Ergebnisse der Regressionsanalyse berichten, oder man sichert die Analyse zusätzlich durch Bootstrapping ab.

Beim Bootstrapping werden aus den vorhandenen Daten Zufallsstichproben gezogen, und zwar viele tausend Male. Basierend auf diesen Bootstrap-Samples erhalten wir eine Verteilung der Schätzungen für jeden Parameter unseres Regressionsmodells und können dafür die Konfidenzintervalle berechnen. Damit erhalten wir Informationen über die Streuung und Unsicherheit unserer Schätzwerte.

In R können wir Bootstrapping mit der Funktion "Boot" aus dem Paket "car" anwenden. Diese Funktion erzeugt die Bootstrap-Samples aus den Originaldaten und berechnet zu jedem dieser Samples eine Regression. Wir müssen lediglich in den Argumenten zum Befehl "Boot" unser Orginalmodell ("model") spezifizieren und die Zahl der gewünschten Wiederholungen (R = 2000) angeben. Alle erzeugten Bootstraps speichern wir in einem Objekt mit dem Namen "bootReg".

Die Funktion "summary" gibt uns dann eine Zusammenfassung über das Bootstrapping. Zusätzlich berechnen wir mit der Funktion "confint()" die Konfidenzintervalle für die Bootstrap-Regressionskoeffizienten. Wir geben zwei Argumente an: das Objekt "bootReg", für das die Koeffizienten berechnet werden sollen und das gewünschte Konfidenzniveau "level = 0.95".

```{r Bootstrapping}
#Alternativ: Bootstrapping!
bootReg <- Boot(model, R=2000)
summary(bootReg)
confint(bootReg, level = 0.95)
```

In der Interpretation konzentrieren wir uns auf die Konfidenzintervalle des Bootstrappings. Im ausgegebenen Dataframe sehen wir die unteren und oberen Grenzen der Konfidenzintervalle für jeden Koeffizienten. Dies zeigt den Bereich an, in den der jeweilige Parameter mit großer Sicherheit fällt. Wenn ein 95%-Konfidenzintervall 0 nicht mit einschließt, können wir davon ausgehen, dass der Koeffizient auf einem Signifikanzniveau von .05 signifikant ist. Dies ist bei unserem Beispiel der Fall. Wir haben also unsere Regressionsanalyse zusätzlich mit Bootstrapping abgesichert.

## Zum Nachlesen

Kapitel 7 in: Fields, A. (2012). Discovering Statistics Using R. Sage.

## Hausübung 5

Jetzt sind Sie dran! Prüfen Sie mit einer einfachen Regressionsanalyse anhand desselben Datensatzes, ob die Internetnutzung der Befragten (netustm) einen Einfluss auf das Vertrauen in ihre eigenen Fähigkeiten zur politischen Partizipation hat (cptppola).

1.  Legen Sie unabhängige und abhängige Variablen fest. Denken Sie daran ggfs. fehlende Werte umzukodieren. Tipp: Prüfen Sie die Codes für fehlende Werte im Codebuch!

```{r UVs und AVs}
#UVs und AV definieren

```

2.  Wie lauten die Null- und die Alternativhypothese?

Antwort: ...

3.  Berechnen Sie die deskriptiven Statistiken für UV und AV. Schließen Sie ggfs. fehlende Werte für die weiteren Analysen aus.

```{r Deskriptive Stats}
#Deskriptive Statistiken

#Ausschluss von Fällen mit fehlenden Werten

```

4.  Besteht ein linearer Zusammenhang zwischen UV und AV? Stellen Sie diesen graphisch dar.

Antwort:...

```{r scatterplot}
#Streudiagramm erstellen

```

5.  Führen Sie nun die Regressionsanalyse durch. Wie interpretieren Sie die Ergebnisse inhaltlich? Gehen Sie dabei auf alle wichtigen Koeffizienten ein.

Antwort: ...

```{r Regressionsmodell}
#Regressionsanalyse durchführen

```

6.  Prüfen Sie die weiteren Voraussetzungen der Regressionsanalyse anhand der diagnostischen Plots und ggfs. weiterer Tests. Beurteilen Sie, wie die Voraussetzungen erfüllt werden und welche Konsequenzen ggfs. gezogen werden müssen.

Antwort: ...

```{r Residuen}
#

```

**Wichtig!** Speichern Sie das angepasste Markdown mit einem Dateinamen nach dem folgenden Muster: Nachname_Übung5.Rmd Laden Sie diese Datei in den dafür vorgesehenen Ordner in Moodle.
