---
title: "Übung 6: Multiple Regression"
author: "Annie Waldherr"
output:
html_document: default
date: "2024-05-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Überblick und Lernziele

Dieses Tutorial gibt eine Einführung in die multiple Regressionsanalyse. Sie lernen, wie man:

-   Daten für eine multiple Regressionsanalyse vorbereitet,
-   eine multiple Regression inklusive der Beta-Koeffizienten berechnet und interpretiert,
-   die Voraussetzungen einer multiplen Regression prüft.

## Das Arbeitsverzeichnis

Wie immer prüfen wir zuerst mit "getwd()", unter welchem Pfad unser Arbeitsverzeichnis ist. Alle Skripte und Datensätze, mit denen wir arbeiten wollen, sollten in diesem Ordner abgelegt sein.

```{r Working Directory}
##Arbeitsverzeichnis checken
getwd()
```

## Pakete installieren und laden

Dann laden wir wieder mit dem Paket "pacman" die nötigen R-Pakete.

```{r Pakete installieren}
##Pakete installieren und laden
if (!require("pacman")) {install.packages("pacman"); library(pacman)}
p_load(tidyverse, car, lmtest, QuantPsyc)
```

## Daten einlesen

Für diese Übung verwenden wir wieder den Datensatz aus dem European Social Survey: ESS Round 8 (2016): integrated file, edition 2.3, zu finden unter: <https://ess-search.nsd.no/en/study/f8e11f55-0c14-4ab3-abde-96d3f14d3c76>

Wir arbeiten mit dem gefilterten Datensatz aus Übung 5 weiter, der die folgenden Variablen für die österreichischen Befragten enthält: Gender (gndr), Age of respondent calculated (agea), News about politics and current affairs (nwspol), Internet use (netustm), Confident in own ability to participate (cptppola).

```{r Daten laden}
#Datensatz laden
df <- read.csv("ESS8e02_3_AT.csv")
```

```{r Daten inspizieren, eval=FALSE}
#Datensatz inspizieren
glimpse(df)
class(df)
head(df)
View(df)
```

## UV und AV definieren

Wir rechnen eine Regressionsanalyse mit den folgenden UVs: Gender (gndr), Age of respondent calculated (agea), News about politics and current affairs (nwspol), Internet use (netustm) und der AV: Confident in own ability to participate (cptppola).

Mit dem unten stehenden Code, der Ihnen aus den vorigen Übungen bekannt ist, definieren wir unsere UV und AV und vergeben die zugehörigen Labels.

```{r Variablen auswählen}
#UV und AV definieren
df$uv1 <- df$nwspol
df$uv2 <- df$netustm
df$uv3 <- df$gndr
df$uv4 <- df$agea

df$av <- df$cptppola

#Labels vergeben
label_uv1 <- "Politischer Nachrichtenkonsum"
label_uv2 <- "Internetnutzung"
label_uv3 <- "Geschlecht"
label_uv4 <- "Alter"

label_av <- "Partizipationsfähigkeit"

glimpse(df)
```

Als nächstes definieren wir mit der Funktion "Recode" wieder die fehlenden/ungültigen Werte als "NA". Um diese Werte zu indentifizieren, hilft uns wieder ein Blick ins zugehörige Codebuch.

```{r fehlende Werte}
#Fehlende Werte umkodieren
df$uv1 <- Recode((df$uv1), 
                '7777 = NA; 8888 = NA; 9999 = NA')
df$uv2 <- Recode((df$uv2), 
                '6666= NA; 7777 = NA; 8888 = NA; 9999 = NA')
df$uv3 <- Recode((df$uv3), 
                '9 = NA')
df$uv4 <- Recode((df$uv4), 
                '999 = NA')

df$av <- Recode((df$av), 
                '7 = NA; 8 = NA; 9 = NA')

glimpse(df)
```

Für die weiteren Analysen schließen wir die Fälle mit fehlenden Werten aus. Dies erreichen wir wieder mit der Funktion "drop_na", die wir auf beide Variablen, UV und AV, anwenden. Es werden also alle Fälle ausgeschlossen, die fehlende Werte in einer der UVs oder der AV aufweisen.

```{r Fehlende Werte ausschließen}

#Fälle mit fehlenden Werten ausschließen

df <- drop_na(df, uv1, uv2, uv3, uv4, av)
```

## Datenexploration

Um einen ersten Eindruck über die Verteilungen der Daten zu gewinnen, erstellen wir Boxplots für die AV und die metrischen UVs.

Haben alle Variablen das nötige Skalenniveau?

```{r Boxplots}

boxplot(df$av, main = label_av)
boxplot(df$uv1, main = label_uv1)
boxplot(df$uv2, main = label_uv2)
boxplot(df$uv4, main = label_uv4)
```

## Multiple Regression

Um die Regression durchzuführen, verwenden wir wieder die Funktion "lm" (linear model) und weisen sie einem Objekt zu, welches wir "model" nennen. Die AV fügen wir vor der Tilde, die UVs hinter der Tilde ein. Mehrere UVs kombinieren wir mit einem Pluszeichen. Als Datensatz verwenden wir wieder "df". Anschließend wenden wir die Funktion "summary" auf das Objekt "model" an. Damit erhalten wir die Zusammenfassung der Ergebnisse.

```{r Multiple Regression}
model <- lm(av ~ uv1 + uv2 + uv3 + uv4, data = df)
summary(model)
```

Der Output entspricht dem der einfachen Regressionsanalyse. In der Tabelle der Koeffizienten finden wir nun die entsprechenden Werte für alle unsere UVs gelistet: in der ersten Spalte die unstandardisierten B-Koeffizienten, dann die Standardfehler, t-Werte und die korrespondierenden p-Werte, die uns sagen, ob die Regressionskoeffizienten signifikant sind.

Unter der Tabelle finden wir wieder die weiteren Informationen zum Standardfehler der Residuen, zur Güte des Modells (R-Quadrat) und die F-Statistik zum zugehörigen Regressionsmodell. Hier interessieren uns v.a. die Informationen zum R-Quadrat, das uns angibt wieviel der Varianz in der AV durch unser Regressionsmodell erklärt wird. Zur Erinnerung: wir berichten immer das korrigierte R-Quadrat!

Wie interpretieren Sie die Ergebnisse der multiplen Regression?

Um mehrere Regressionskoeffizienten sinnvoll vergleichen zu können, müssen wir sie standardisieren. Standardisierte Regressionskoeffizienten (Beta-Koeffizienten) erhalten wir mit der Funktion "lm.beta" aus dem QuantPsyc-Paket. Wir wenden diese auf unser Regressionsmodell an.

```{r standardisierte Koeffizienten}
lm.beta(model)
```

Die Beta-Koeffizienten geben Veränderungen in Standardabweichungen an und liegen meist zwischen -1 und +1. Sie geben den Einfluss der UV auf unsere AV an, bereinigt um den Einfluss der weiteren UVs. Wir können sie interpretieren wie Korrelationskoeffizienten (\< 0.1 kein Einfluss, 0.1 - 0.3 schwach, 0.3 - 0.5 moderat, \> 0.5 stark).

UV1 ist unser stärkster Prädiktor mit β = 0.14, p \< 0.001. Politischer Nachrichtenkonsum hat also einen schwach positiven Einfluss auf das Vertrauen in die eigene Partizipationsfähigkeit. Darauf folgt UV2 (Internetnutzung) mit β = 0.10, p \< 0.001. Die beiden demographischen Variablen Geschlecht (UV3) und Alter (UV4) haben ebenfalls einen signifikanten, aber schwächeren Einfluss.

**Achtung!** Da Geschlecht eine dichotome Variable ist, müssen wir das bei der Interpretation berücksichtigen. Dem Codebuch zum Datensatz entnehmen wir, dass 1 = männlich und 2 = weiblich. Das negative Vorzeichen bedeutet also, dass Männer ihre eigene Partizipationsfähigkeit ein kleines bisschen höher einschätzen, wenn man alle anderen Faktoren konstant hält.

## Residuenanalyse zur Voraussetzungsprüfung

Wir prüfen nun die Voraussetzungen mit Hilfe der diagnostischen Plots wie in Übung 5.

Wie interpretieren Sie die Plots in Bezug auf: -Homoskedastizität? -Normalverteilung der Residuen? -Ausreißer?

```{r Residualplots}
plot(model)
```

Zusätzlich können wir die Tests auf Homoskedastizität (Breuch-Pagan Test) und Normalverteilung (Shapiro-Wilk) der Residuen durchführen.

```{r Homoskedastizität}
bptest(model)
#Breusch-Pagan Test auf Homoskedastizität

shapiro.test(residuals(model))
#Test auf Normalverteilung der Residuen
```

Beide Tests sind signifikant, d.h. die beiden Annahmen der Homoskedastizität und der Normalverteilung der Residuen werden verletzt. Nun kann man entweder mit dem Hinweis auf die Robustheit der Regressionsanalyse auf Verletzung ihrer Annahmen dennoch die Ergebnisse der Regressionsanalyse berichten, oder man sichert die Analyse zusätzlich durch Bootstrapping ab (für eine ausführliche Erläuterung des unten folgenden Codes und die Interpretation des Outputs siehe Übung 5).

```{r Bootstrapping}
#Alternative: Bootstrapping!
bootReg <- Boot(model, R=2000)
summary(bootReg)
confint(bootReg, level = 0.95)
```

In der Interpretation konzentrieren wir uns auf die Konfidenzintervalle des Bootstrappings. Was fällt Ihnen auf?

## Multikollinearität

Bei der multiplen Regression gibt es noch eine weitere Voraussetzung, die wir prüfen müssen, und zwar sollten die UVs möglichst unabhängig voneinander sein, d.h. nicht hoch miteinander korrelieren.

Multikollinearität nennt man das Auftreten einer hohen Korrelation zwischen zwei oder mehreren unabhängigen Variablen in einem multiplen Regressionsmodell. Dies ist nicht erwünscht, denn es erschwert es, die Effekte der verschiedenen Variablen voneinander zu unterscheiden. Dies führt zu unsicheren und verzerrten Schätzungen der Regressionskoeffizienten.

Um zu testen, ob Multikollinearität vorliegt, berechnen wir den Variance Inflation Factor (VIF) für die UVs. Wir verwenden dazu die Funktion "vif" aus dem Paket "car".

```{r VIF}
vif(model)
```

Der VIF-Wert gibt an, ob ein Prädiktor einen starken linearen Zusammenhang mit den anderen Prädiktoren aufweist. Der kleinstmögliche VIF-Wert ist 1 (keine Multikollinearität). Als Faustregel gilt, dass ein VIF-Wert von über 5 oder 10 problematisch ist.

Unsere VIF-Werte liegen alle nah bei 1, d.h. es liegt keine Multikollinearität vor.

## Zum Nachlesen

Kapitel 7 in: Fields, A. (2012). Discovering Statistics Using R. Sage.

## Hausübung 6

Jetzt sind Sie dran!

1.  Erstellen Sie aus dem Ursprungsdatensatz "ESS8e02_3.csv" (Sie finden ihn auch im Moodle-Ordner zu Übung 6) einen neuen gefilterten Datensatz für die österreichischen Befragten, der außer den bisherigen Variablen (gndr, agea, nwspol, netustm, cptppola) auch die UV politisches Interesse (polintr; how interested in politics) enthält.

```{r Datensatz erstellen}
#Daten filtern und Variablen auswählen

```

2.  Rekodieren und entfernen Sie die ungültigen/fehlenden Werte für alle Variablen und legen Sie UVs (gndr, agea, nwspol, netustm, polintr) und AV (cptppola) fest.

```{r fehlende Werte und Variablen}
#Fehlende Werte rekodieren

#Fehlende Werte entfernen

#UVs und AV definieren
```

3.  Berechnen Sie nun ein Regressionsmodell mit den UVs gndr, agea und polintr, inklusive der standardisierten Regressionskoeffizienten. Wie interpretieren Sie die Ergebnisse?

Antwort: ...

```{r Model1}
#Multiple Regression

#Standardisierte Regressionskoeffizienten

```

4.  Berechnen Sie nun ein weiteres Regressionsmodell mit allen UVs (gendr, agea, polintr, nwspol, netustm). Wie verändern sich die Ergebnisse im Vergleich zu Modell 1?

Antwort: ...

```{r Model2}
#Multiple Regression

#Standardisierte Regressionskoeffizienten

```

5.  Erstellen und interpretieren Sie die diagnostischen Plots für das zweite Modell mit allen UVs.

Antwort:...

```{r diagnostische Plots}
#Analyse der Residuen

```

6.  Prüfen Sie, ob Multikollinearität im zweiten, vollständigen Modell ein Problem ist.

Antwort: ...

```{r Multikollinearität}
#Multikollinearität prüfen

```

**Wichtig!** Speichern Sie das angepasste Markdown mit einem Dateinamen nach dem folgenden Muster: Nachname_Übung6.Rmd Laden Sie diese Datei in den dafür vorgesehenen Ordner in Moodle.
